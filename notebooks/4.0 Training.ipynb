{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ITF712-Classification-Project/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "project_root_dir = Path(os.path.abspath('')).resolve()\n",
    "print(project_root_dir)\n",
    "\n",
    "sys.path.append(project_root_dir)\n",
    "#sys.path.append(os.path.join(project_root_dir, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-89ca76b4f737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegressionClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVM\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRFClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from src.models.LogisticRegression import LogisticRegressionClassifier\n",
    "from src.models.SVM import SVMClassifier\n",
    "from src.models.RandomForest import RFClassifier\n",
    "from src.models.MLP import MLP\n",
    "from src.models.KN import KN\n",
    "from src.models.DecisionTree import DT\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used throughout the notebook\n",
    "project_root_dir = Path(os.path.abspath('')).resolve().parents[0]\n",
    "current_notebook = \"Training\"\n",
    "\n",
    "# output path for images\n",
    "image_folder_path = os.path.join(project_root_dir, \"notebooks\", current_notebook)\n",
    "os.makedirs(image_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_score(name, score):\n",
    "    score_string = name + ': '\n",
    "    for key in score:\n",
    "        score_string += key + '={:.4f}'.format(score[key]) + '\\t'\n",
    "\n",
    "    print(score_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict_from_results(name, score):\n",
    "    score['name'] = name\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "data_path = os.path.join(project_root_dir, 'data', 'processed')\n",
    "\n",
    "data = pd.read_csv(os.path.join(data_path, 'training_data.csv'))\n",
    "labels = pd.read_csv(os.path.join(data_path, 'training_labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>7.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.364312e-17</td>\n",
       "      <td>1.300867e-16</td>\n",
       "      <td>1.014901e-16</td>\n",
       "      <td>-5.719331e-17</td>\n",
       "      <td>1.166295e-16</td>\n",
       "      <td>-5.607187e-17</td>\n",
       "      <td>-1.794300e-17</td>\n",
       "      <td>-5.831474e-17</td>\n",
       "      <td>6.055762e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.252168e-17</td>\n",
       "      <td>6.728624e-17</td>\n",
       "      <td>-2.018587e-17</td>\n",
       "      <td>5.382900e-17</td>\n",
       "      <td>-2.063445e-16</td>\n",
       "      <td>1.087794e-16</td>\n",
       "      <td>-1.570012e-17</td>\n",
       "      <td>2.018587e-17</td>\n",
       "      <td>4.934325e-17</td>\n",
       "      <td>-1.401797e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000632</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "      <td>1.000632e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.881617</td>\n",
       "      <td>-7.342717e-01</td>\n",
       "      <td>-1.240112e+00</td>\n",
       "      <td>-8.066802e-01</td>\n",
       "      <td>-7.626971e-01</td>\n",
       "      <td>-7.345422e-01</td>\n",
       "      <td>-1.095629e+00</td>\n",
       "      <td>-3.792727e-01</td>\n",
       "      <td>-8.283998e-01</td>\n",
       "      <td>-1.154050e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.656381e-01</td>\n",
       "      <td>-2.606863e-01</td>\n",
       "      <td>-7.002438e-01</td>\n",
       "      <td>-4.547012e-01</td>\n",
       "      <td>-1.046938e+00</td>\n",
       "      <td>-2.332711e-01</td>\n",
       "      <td>-2.344170e-01</td>\n",
       "      <td>-5.220187e-01</td>\n",
       "      <td>-6.579067e-01</td>\n",
       "      <td>-8.594620e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.781026</td>\n",
       "      <td>-6.841764e-01</td>\n",
       "      <td>-7.047405e-01</td>\n",
       "      <td>-6.046400e-01</td>\n",
       "      <td>-6.580867e-01</td>\n",
       "      <td>-7.345422e-01</td>\n",
       "      <td>-7.569981e-01</td>\n",
       "      <td>-3.792727e-01</td>\n",
       "      <td>-6.039509e-01</td>\n",
       "      <td>-7.929953e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.656381e-01</td>\n",
       "      <td>-2.606863e-01</td>\n",
       "      <td>-6.572363e-01</td>\n",
       "      <td>-4.547012e-01</td>\n",
       "      <td>-7.272258e-01</td>\n",
       "      <td>-2.332711e-01</td>\n",
       "      <td>-2.344170e-01</td>\n",
       "      <td>-5.220187e-01</td>\n",
       "      <td>-6.579067e-01</td>\n",
       "      <td>-8.166401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.378613</td>\n",
       "      <td>-4.336742e-01</td>\n",
       "      <td>-3.223209e-01</td>\n",
       "      <td>-3.352186e-01</td>\n",
       "      <td>-3.442556e-01</td>\n",
       "      <td>-4.358417e-01</td>\n",
       "      <td>-3.054330e-01</td>\n",
       "      <td>-3.792727e-01</td>\n",
       "      <td>-1.550532e-01</td>\n",
       "      <td>-1.911757e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.886857e-01</td>\n",
       "      <td>-2.606863e-01</td>\n",
       "      <td>-4.423305e-01</td>\n",
       "      <td>-4.161063e-01</td>\n",
       "      <td>-2.157383e-01</td>\n",
       "      <td>-2.332711e-01</td>\n",
       "      <td>-2.344170e-01</td>\n",
       "      <td>-4.211254e-01</td>\n",
       "      <td>-4.445670e-01</td>\n",
       "      <td>-3.030405e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.426161</td>\n",
       "      <td>2.802158e-01</td>\n",
       "      <td>4.424790e-01</td>\n",
       "      <td>2.035897e-01</td>\n",
       "      <td>1.788499e-01</td>\n",
       "      <td>3.202531e-01</td>\n",
       "      <td>4.847627e-01</td>\n",
       "      <td>-3.792727e-01</td>\n",
       "      <td>6.939565e-02</td>\n",
       "      <td>5.309956e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.919588e-02</td>\n",
       "      <td>-2.606863e-01</td>\n",
       "      <td>2.562342e-01</td>\n",
       "      <td>-1.075048e-01</td>\n",
       "      <td>3.597179e-01</td>\n",
       "      <td>-2.332711e-01</td>\n",
       "      <td>-2.344170e-01</td>\n",
       "      <td>8.339310e-02</td>\n",
       "      <td>2.664437e-01</td>\n",
       "      <td>4.246247e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.444026</td>\n",
       "      <td>4.526119e+00</td>\n",
       "      <td>3.807779e+00</td>\n",
       "      <td>5.052796e+00</td>\n",
       "      <td>5.200577e+00</td>\n",
       "      <td>5.202191e+00</td>\n",
       "      <td>4.209929e+00</td>\n",
       "      <td>1.077247e+01</td>\n",
       "      <td>6.803321e+00</td>\n",
       "      <td>4.863900e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.205956e+00</td>\n",
       "      <td>9.794375e+00</td>\n",
       "      <td>6.908617e+00</td>\n",
       "      <td>7.453904e+00</td>\n",
       "      <td>5.922832e+00</td>\n",
       "      <td>9.088584e+00</td>\n",
       "      <td>1.268766e+01</td>\n",
       "      <td>9.189677e+00</td>\n",
       "      <td>5.670489e+00</td>\n",
       "      <td>4.276973e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          margin1       margin2       margin3       margin4       margin5  \\\n",
       "count  792.000000  7.920000e+02  7.920000e+02  7.920000e+02  7.920000e+02   \n",
       "mean     0.000000  3.364312e-17  1.300867e-16  1.014901e-16 -5.719331e-17   \n",
       "std      1.000632  1.000632e+00  1.000632e+00  1.000632e+00  1.000632e+00   \n",
       "min     -0.881617 -7.342717e-01 -1.240112e+00 -8.066802e-01 -7.626971e-01   \n",
       "25%     -0.781026 -6.841764e-01 -7.047405e-01 -6.046400e-01 -6.580867e-01   \n",
       "50%     -0.378613 -4.336742e-01 -3.223209e-01 -3.352186e-01 -3.442556e-01   \n",
       "75%      0.426161  2.802158e-01  4.424790e-01  2.035897e-01  1.788499e-01   \n",
       "max      3.444026  4.526119e+00  3.807779e+00  5.052796e+00  5.200577e+00   \n",
       "\n",
       "            margin6       margin7       margin8       margin9      margin10  \\\n",
       "count  7.920000e+02  7.920000e+02  7.920000e+02  7.920000e+02  7.920000e+02   \n",
       "mean   1.166295e-16 -5.607187e-17 -1.794300e-17 -5.831474e-17  6.055762e-17   \n",
       "std    1.000632e+00  1.000632e+00  1.000632e+00  1.000632e+00  1.000632e+00   \n",
       "min   -7.345422e-01 -1.095629e+00 -3.792727e-01 -8.283998e-01 -1.154050e+00   \n",
       "25%   -7.345422e-01 -7.569981e-01 -3.792727e-01 -6.039509e-01 -7.929953e-01   \n",
       "50%   -4.358417e-01 -3.054330e-01 -3.792727e-01 -1.550532e-01 -1.911757e-01   \n",
       "75%    3.202531e-01  4.847627e-01 -3.792727e-01  6.939565e-02  5.309956e-01   \n",
       "max    5.202191e+00  4.209929e+00  1.077247e+01  6.803321e+00  4.863900e+00   \n",
       "\n",
       "       ...     texture55     texture56     texture57     texture58  \\\n",
       "count  ...  7.920000e+02  7.920000e+02  7.920000e+02  7.920000e+02   \n",
       "mean   ...  3.252168e-17  6.728624e-17 -2.018587e-17  5.382900e-17   \n",
       "std    ...  1.000632e+00  1.000632e+00  1.000632e+00  1.000632e+00   \n",
       "min    ... -5.656381e-01 -2.606863e-01 -7.002438e-01 -4.547012e-01   \n",
       "25%    ... -5.656381e-01 -2.606863e-01 -6.572363e-01 -4.547012e-01   \n",
       "50%    ... -4.886857e-01 -2.606863e-01 -4.423305e-01 -4.161063e-01   \n",
       "75%    ...  6.919588e-02 -2.606863e-01  2.562342e-01 -1.075048e-01   \n",
       "max    ...  6.205956e+00  9.794375e+00  6.908617e+00  7.453904e+00   \n",
       "\n",
       "          texture59     texture60     texture61     texture62     texture63  \\\n",
       "count  7.920000e+02  7.920000e+02  7.920000e+02  7.920000e+02  7.920000e+02   \n",
       "mean  -2.063445e-16  1.087794e-16 -1.570012e-17  2.018587e-17  4.934325e-17   \n",
       "std    1.000632e+00  1.000632e+00  1.000632e+00  1.000632e+00  1.000632e+00   \n",
       "min   -1.046938e+00 -2.332711e-01 -2.344170e-01 -5.220187e-01 -6.579067e-01   \n",
       "25%   -7.272258e-01 -2.332711e-01 -2.344170e-01 -5.220187e-01 -6.579067e-01   \n",
       "50%   -2.157383e-01 -2.332711e-01 -2.344170e-01 -4.211254e-01 -4.445670e-01   \n",
       "75%    3.597179e-01 -2.332711e-01 -2.344170e-01  8.339310e-02  2.664437e-01   \n",
       "max    5.922832e+00  9.088584e+00  1.268766e+01  9.189677e+00  5.670489e+00   \n",
       "\n",
       "          texture64  \n",
       "count  7.920000e+02  \n",
       "mean  -1.401797e-16  \n",
       "std    1.000632e+00  \n",
       "min   -8.594620e-01  \n",
       "25%   -8.166401e-01  \n",
       "50%   -3.030405e-01  \n",
       "75%    4.246247e-01  \n",
       "max    4.276973e+00  \n",
       "\n",
       "[8 rows x 192 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.595439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          species\n",
       "count  792.000000\n",
       "mean    49.000000\n",
       "std     28.595439\n",
       "min      0.000000\n",
       "25%     24.000000\n",
       "50%     49.000000\n",
       "75%     74.000000\n",
       "max     98.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:Creating\n"
     ]
    }
   ],
   "source": [
    "from src.models.LogisticRegression import LogisticRegressionClassifier\n",
    "\n",
    "lr_clf = LogisticRegressionClassifier(s_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:Initialization\n",
      "Logistic Regression: f1=0.9843\tprecision=0.9848\trecall=0.9874\taccuracy=0.9874\tlog_loss=0.1454\t\n"
     ]
    }
   ],
   "source": [
    "# print results without any optimization\n",
    "lr_clf.cross_validate(data, labels, optimized=False)\n",
    "display_score(lr_clf.name, lr_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(lr_clf.name, lr_clf.get_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will search the best set of hyperparameters with a RandomSearch. \n",
    "# The hyper-parameters have been fitted to have to the best range\n",
    "lr_clf.optimize(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:Initialization\n",
      "Logistic Regression:C:390.01768308021974 penalty:l2 solver:lbfgs \n",
      "Logistic Regression: f1=0.9843\tprecision=0.9848\trecall=0.9874\taccuracy=0.9874\tlog_loss=0.0542\t\n"
     ]
    }
   ],
   "source": [
    "lr_clf.cross_validate(data, labels, optimized=True)\n",
    "display_score(lr_clf.name, lr_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(lr_clf.name, lr_clf.get_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:Creating\n"
     ]
    }
   ],
   "source": [
    "from src.models.SVM import SVMClassifier\n",
    "\n",
    "svm_clf = SVMClassifier(s_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:Initialization\n",
      "SVM: f1=0.9749\tprecision=0.9783\trecall=0.9785\taccuracy=0.9785\tlog_loss=2.5780\t\n"
     ]
    }
   ],
   "source": [
    "# print results without any optimization\n",
    "svm_clf.cross_validate(data, labels, optimized=False)\n",
    "display_score(svm_clf.name, svm_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(svm_clf.name, svm_clf.get_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will search the best set of hyperparameters with a RandomSearch. \n",
    "# The hyper-parameters have been fitted to have to the best range\n",
    "svm_clf.optimize(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:Initialization\n",
      "SVM:probability:True kernel:poly gamma:auto degree:1 C:1.7782794100389228e+74 \n",
      "SVM: f1=0.9808\tprecision=0.9834\trecall=0.9836\taccuracy=0.9836\tlog_loss=2.5311\t\n"
     ]
    }
   ],
   "source": [
    "svm_clf.cross_validate(data, labels, optimized=True)\n",
    "display_score(svm_clf.name, svm_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(svm_clf.name, svm_clf.get_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:Creating\n"
     ]
    }
   ],
   "source": [
    "from src.models.RandomForest import RFClassifier\n",
    "\n",
    "rf_clf = RFClassifier(s_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:Initialization\n",
      "Random Forest: f1=0.9709\tprecision=0.9785\trecall=0.9735\taccuracy=0.9735\tlog_loss=0.9300\t\n"
     ]
    }
   ],
   "source": [
    "# print results without any optimization\n",
    "rf_clf.cross_validate(data, labels, optimized=False)\n",
    "display_score(rf_clf.name, rf_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(rf_clf.name, rf_clf.get_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will search the best set of hyperparameters with a RandomSearch. \n",
    "# The hyper-parameters have been fitted to have to the best range\n",
    "rf_clf.optimize(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:Initialization\n",
      "Random Forest:random_state:42 n_estimators:4000 min_samples_split:2 min_samples_leaf:1 max_features:None max_depth:12 criterion:entropy \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrf_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display_score(rf_clf\u001b[38;5;241m.\u001b[39mname, rf_clf\u001b[38;5;241m.\u001b[39mget_score())\n\u001b[0;32m      4\u001b[0m score_list\u001b[38;5;241m.\u001b[39mappend(build_dict_from_results(rf_clf\u001b[38;5;241m.\u001b[39mname, rf_clf\u001b[38;5;241m.\u001b[39mget_score()))\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\src\\models\\Classifier.py:99\u001b[0m, in \u001b[0;36mClassifier.cross_validate\u001b[1;34m(self, data, labels, optimized)\u001b[0m\n\u001b[0;32m     96\u001b[0m training_data, test_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues[training_index], data\u001b[38;5;241m.\u001b[39mvalues[test_index]\n\u001b[0;32m     97\u001b[0m training_label, test_label \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mvalues[training_index], labels\u001b[38;5;241m.\u001b[39mvalues[test_index]\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[0;32m    102\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict_proba(test_data)\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\repos\\itf712-classification-project\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_clf.cross_validate(data, labels, optimized=True)\n",
    "display_score(rf_clf.name, rf_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(rf_clf.name, rf_clf.get_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:Creating\n"
     ]
    }
   ],
   "source": [
    "from src.models.MLP import MLP\n",
    "\n",
    "mlp_clf = MLP(s_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:Initialization\n",
      "MLP: f1=0.9616\tprecision=0.9688\trecall=0.9659\taccuracy=0.9659\tlog_loss=0.1152\t\n"
     ]
    }
   ],
   "source": [
    "# print results without any optimization\n",
    "mlp_clf.cross_validate(data, labels, optimized=False)\n",
    "display_score(mlp_clf.name, mlp_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(mlp_clf.name, mlp_clf.get_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will search the best set of hyperparameters with a RandomSearch. \n",
    "# The hyper-parameters have been fitted to have to the best range\n",
    "mlp_clf.optimize(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.cross_validate(data, labels, optimized=True)\n",
    "display_score(mlp_clf.name, mlp_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(mlp_clf.name, mlp_clf.get_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KN:Creating\n"
     ]
    }
   ],
   "source": [
    "from src.models.KN import KN\n",
    "\n",
    "kn_clf = KN(s_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KN:Initialization\n",
      "KN: f1=0.9459\tprecision=0.9530\trecall=0.9533\taccuracy=0.9533\tlog_loss=0.3373\t\n"
     ]
    }
   ],
   "source": [
    "# print results without any optimization\n",
    "kn_clf.cross_validate(data, labels, optimized=False)\n",
    "display_score(kn_clf.name, kn_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(kn_clf.name, kn_clf.get_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will search the best set of hyperparameters with a RandomSearch. \n",
    "# The hyper-parameters have been fitted to have to the best range\n",
    "kn_clf.optimize(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_clf.cross_validate(data, labels, optimized=True)\n",
    "display_score(kn_clf.name, mlp_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(kn_clf.name, kn_clf.get_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:Creating\n"
     ]
    }
   ],
   "source": [
    "from src.models.DecisionTree import DT\n",
    "\n",
    "dt_clf = DT(s_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:Initialization\n",
      "Decision Tree: f1=0.5879\tprecision=0.6230\trecall=0.6124\taccuracy=0.6124\tlog_loss=13.3874\t\n"
     ]
    }
   ],
   "source": [
    "# print results without any optimization\n",
    "dt_clf.cross_validate(data, labels, optimized=False)\n",
    "display_score(dt_clf.name, dt_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(dt_clf.name, dt_clf.get_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will search the best set of hyperparameters with a RandomSearch. \n",
    "# The hyper-parameters have been fitted to have to the best range\n",
    "dt_clf.optimize(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.cross_validate(data, labels, optimized=True)\n",
    "display_score(kn_clf.name, mlp_clf.get_score())\n",
    "\n",
    "score_list.append(build_dict_from_results(dt_clf.name, dt_clf.get_score()))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ca-central-1:310906938811:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
